{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResearchTrader API Testing\n",
    "\n",
    "This notebook tests each endpoint of the ResearchTrader API to ensure everything is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import asyncio\n",
    "import json\n",
    "from IPython.display import display, JSON\n",
    "import time\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API configuration\n",
    "API_BASE_URL = \"http://localhost:8000\"\n",
    "\n",
    "# Helper function to display JSON responses nicely\n",
    "def display_json(data):\n",
    "    \"\"\"Display JSON data nicely formatted in the notebook\"\"\"\n",
    "    if data:\n",
    "        display(JSON(data))\n",
    "    else:\n",
    "        print(\"No data to display\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Testing Search Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_search_papers(query=\"reinforcement learning trading\", max_results=5):\n",
    "    \"\"\"Test the search endpoint\"\"\"\n",
    "    print(f\"Testing search endpoint with query: '{query}'\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    async with httpx.AsyncClient(timeout=30.0) as client:\n",
    "        response = await client.get(\n",
    "            f\"{API_BASE_URL}/search/\",\n",
    "            params={\"query\": query, \"max_results\": max_results}\n",
    "        )\n",
    "        \n",
    "        print(f\"Status code: {response.status_code}\")\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"Response time: {elapsed:.2f} seconds\")\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            response_data = response.json()\n",
    "            \n",
    "            # Display summary of results\n",
    "            if \"papers\" in response_data and len(response_data[\"papers\"]) > 0:\n",
    "                papers = response_data[\"papers\"]\n",
    "                print(f\"Found {len(papers)} papers\")\n",
    "                \n",
    "                # Return the first paper ID for use in other tests\n",
    "                paper_id = papers[0][\"id\"]\n",
    "                print(f\"First paper ID: {paper_id}\")\n",
    "                print(f\"Title: {papers[0]['title']}\")\n",
    "                \n",
    "                return paper_id, response_data\n",
    "            else:\n",
    "                print(\"No papers found or error in response structure\")\n",
    "                return None, response_data\n",
    "        else:\n",
    "            print(f\"Error: {response.text}\")\n",
    "            return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing search endpoint with query: 'momentum trading strategies'\n",
      "Status code: 200\n",
      "Response time: 2.64 seconds\n",
      "Found 5 papers\n",
      "First paper ID: http://arxiv.org/abs/2504.10789v1\n",
      "Title: Can Large Language Models Trade? Testing Financial Theories with LLM Agents in Market Simulations\n",
      "\n",
      "Detailed search results:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "papers": [
        {
         "authors": [
          "Alejandro Lopez-Lira"
         ],
         "category": "q-fin.CP",
         "id": "http://arxiv.org/abs/2504.10789v1",
         "link": "http://arxiv.org/abs/2504.10789v1",
         "pdf_url": "http://arxiv.org/pdf/2504.10789v1",
         "published": "2025-04-15T01:18:36Z",
         "summary": "This paper presents a realistic simulated stock market where large language\nmodels (LLMs) act as heterogeneous competing trading agents. The open-source\nframework incorporates a persistent order book with market and limit orders,\npartial fills, dividends, and equilibrium clearing alongside agents with varied\nstrategies, information sets, and endowments. Agents submit standardized\ndecisions using structured outputs and function calls while expressing their\nreasoning in natural language. Three findings emerge: First, LLMs demonstrate\nconsistent strategy adherence and can function as value investors, momentum\ntraders, or market makers per their instructions. Second, market dynamics\nexhibit features of real financial markets, including price discovery, bubbles,\nunderreaction, and strategic liquidity provision. Third, the framework enables\nanalysis of LLMs' responses to varying market conditions, similar to partial\ndependence plots in machine-learning interpretability. The framework allows\nsimulating financial theories without closed-form solutions, creating\nexperimental designs that would be costly with human participants, and\nestablishing how prompts can generate correlated behaviors affecting market\nstability.",
         "title": "Can Large Language Models Trade? Testing Financial Theories with LLM Agents in Market Simulations"
        },
        {
         "authors": [
          "Travis Cable",
          "Amir Mani",
          "Wei Qi",
          "Georgios Sotiropoulos",
          "Yiyuan Xiong"
         ],
         "category": "q-fin.PM",
         "id": "http://arxiv.org/abs/2504.06289v1",
         "link": "http://arxiv.org/abs/2504.06289v1",
         "pdf_url": "http://arxiv.org/pdf/2504.06289v1",
         "published": "2025-04-03T20:33:30Z",
         "summary": "United States (US) IG bonds typically trade at modest spreads over US\nTreasuries, reflecting the credit risk tied to a corporation's default\npotential. During market crises, IG spreads often widen and liquidity tends to\ndecrease, likely due to increased credit risk (evidenced by higher IG Credit\nDefault Index spreads) and the necessity for asset holders like mutual funds to\nliquidate assets, including IG credits, to manage margin calls, bolster cash\nreserves, or meet redemptions. These credit and liquidity premia occur during\nmarket drawdowns and tend to move non-linearly with the market. The research\nherein refers to this non-linearity (during periods of drawdown) as downside\nconvexity, and shows that this market behavior can effectively be captured\nthrough a short position established in IG Exchange Traded Funds (ETFs).\n  The following document details the construction of three signals: Momentum,\nLiquidity, and Credit, that can be used in combination to signal entries and\nexits into short IG positions to hedge a typical active bond portfolio (such as\nPIMIX). A dynamic hedge initiates the short when signals jointly correlate and\npoint to significant future hedged return. The dynamic hedge removes when the\nshort position's predicted hedged return begins to mean revert. This systematic\nhedge largely avoids IG Credit drawdowns, lowers absolute and downside risk,\nincreases annualised returns and achieves higher Sortino ratios compared to the\nbenchmark funds. The method is best suited to high carry, high active risk\nfunds like PIMIX, though it also generalises to more conservative funds similar\nto DODIX.",
         "title": "On the Efficacy of Shorting Corporate Bonds as a Tail Risk Hedging Solution"
        }
       ],
       "query": "momentum trading strategies",
       "total_count": 5
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run the search test\n",
    "paper_id, search_results = await test_search_papers(\"momentum trading strategies\")\n",
    "\n",
    "# Display full results\n",
    "if search_results:\n",
    "    print(\"\\nDetailed search results:\")\n",
    "    # Only show the first 2 papers to keep output manageable\n",
    "    search_results_limited = search_results.copy()\n",
    "    if \"papers\" in search_results_limited and len(search_results_limited[\"papers\"]) > 2:\n",
    "        search_results_limited[\"papers\"] = search_results_limited[\"papers\"][:2]\n",
    "    display_json(search_results_limited)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Testing Paper Retrieval by ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_get_paper(paper_id):\n",
    "    \"\"\"Test getting a specific paper by ID\"\"\"\n",
    "    if not paper_id:\n",
    "        print(\"No paper ID provided\")\n",
    "        return None\n",
    "        \n",
    "    print(f\"Testing get paper endpoint for ID: {paper_id}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    async with httpx.AsyncClient(timeout=30.0) as client:\n",
    "        response = await client.get(f\"{API_BASE_URL}/search/{paper_id}\")\n",
    "        \n",
    "        print(f\"Status code: {response.status_code}\")\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"Response time: {elapsed:.2f} seconds\")\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            paper = response.json()\n",
    "            print(f\"Paper title: {paper.get('title', 'N/A')}\")\n",
    "            print(f\"Authors: {', '.join(paper.get('authors', []))}\")\n",
    "            return paper\n",
    "        else:\n",
    "            print(f\"Error fetching paper: {response.text}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing get paper endpoint for ID: 2504.10789v1\n",
      "Status code: 200\n",
      "Response time: 4.93 seconds\n",
      "Paper title: Can Large Language Models Trade? Testing Financial Theories with LLM Agents in Market Simulations\n",
      "Authors: Alejandro Lopez-Lira\n",
      "\n",
      "Detailed paper information:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "authors": [
        "Alejandro Lopez-Lira"
       ],
       "category": "q-fin.CP",
       "id": "http://arxiv.org/abs/2504.10789v1",
       "link": "http://arxiv.org/abs/2504.10789v1",
       "pdf_url": "http://arxiv.org/pdf/2504.10789v1",
       "published": "2025-04-15T01:18:36Z",
       "summary": "This paper presents a realistic simulated stock market where large language\nmodels (LLMs) act as heterogeneous competing trading agents. The open-source\nframework incorporates a persistent order book with market and limit orders,\npartial fills, dividends, and equilibrium clearing alongside agents with varied\nstrategies, information sets, and endowments. Agents submit standardized\ndecisions using structured outputs and function calls while expressing their\nreasoning in natural language. Three findings emerge: First, LLMs demonstrate\nconsistent strategy adherence and can function as value investors, momentum\ntraders, or market makers per their instructions. Second, market dynamics\nexhibit features of real financial markets, including price discovery, bubbles,\nunderreaction, and strategic liquidity provision. Third, the framework enables\nanalysis of LLMs' responses to varying market conditions, similar to partial\ndependence plots in machine-learning interpretability. The framework allows\nsimulating financial theories without closed-form solutions, creating\nexperimental designs that would be costly with human participants, and\nestablishing how prompts can generate correlated behaviors affecting market\nstability.",
       "title": "Can Large Language Models Trade? Testing Financial Theories with LLM Agents in Market Simulations"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run the get paper test\n",
    "paper = await test_get_paper('2504.10789v1')\n",
    "\n",
    "# Display full paper details\n",
    "if paper:\n",
    "    print(\"\\nDetailed paper information:\")\n",
    "    display_json(paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing Paper Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_paper_summary(paper_id, force_refresh=False):\n",
    "    \"\"\"Test generating paper summary\"\"\"\n",
    "    if not paper_id:\n",
    "        print(\"No paper ID provided\")\n",
    "        return None\n",
    "        \n",
    "    print(f\"Testing summary endpoint for paper ID: {paper_id}\")\n",
    "    print(f\"Force refresh: {force_refresh}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    async with httpx.AsyncClient(timeout=120.0) as client:  # Longer timeout for LLM processing\n",
    "        response = await client.get(\n",
    "            f\"{API_BASE_URL}/summarize/{paper_id}\",\n",
    "            params={\"force_refresh\": force_refresh}\n",
    "        )\n",
    "        \n",
    "        print(f\"Status code: {response.status_code}\")\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"Response time: {elapsed:.2f} seconds\")\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            summary = response.json()\n",
    "            # Display key information\n",
    "            print(f\"Using full text: {summary.get('has_full_text', False)}\")\n",
    "            print(f\"Objective: {summary.get('objective', 'N/A')[:100]}...\")\n",
    "            print(f\"Methods: {len(summary.get('methods', []))} items\")\n",
    "            print(f\"Results: {len(summary.get('results', []))} items\")\n",
    "            print(f\"Trading applications: {len(summary.get('trading_applications', []))} items\")\n",
    "            print(f\"Implementation complexity: {summary.get('implementation_complexity', 'N/A')}\")\n",
    "            print(f\"Keywords: {', '.join(summary.get('keywords', []))}\")\n",
    "            return summary\n",
    "        else:\n",
    "            print(f\"Error generating summary: {response.text}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing summary endpoint for paper ID: 2504.10789v1\n",
      "Force refresh: False\n",
      "Status code: 200\n",
      "Response time: 12.75 seconds\n",
      "Using full text: True\n",
      "Objective: To test the capabilities of large language models (LLMs) as trading agents in a simulated financial ...\n",
      "Methods: 5 items\n",
      "Results: 5 items\n",
      "Trading applications: 5 items\n",
      "Implementation complexity: Medium\n",
      "Keywords: Large Language Models, Agent-Based Trading, Market Simulation, Price Discovery, Systemic Risk, Trading Strategies, Market Dynamics, AI Trading\n",
      "\n",
      "Methods:\n",
      "- Open-source simulation framework for agent-based trading\n",
      "- Continuous double-auction market mechanism\n",
      "- Prompt engineering for defining agent strategies\n",
      "- Structured output format for agent decision-making\n",
      "- Comprehensive data collection and analysis system\n",
      "\n",
      "Trading Applications:\n",
      "- Development of LLM-based trading systems that can adapt to various market conditions.\n",
      "- Utilization of the framework for backtesting and validating trading strategies.\n",
      "- Exploration of new trading strategies based on LLM decision-making patterns.\n",
      "- Implementation of risk management protocols to mitigate potential systemic risks from LLM trading.\n",
      "- Integration of LLMs into existing trading platforms for enhanced decision-making capabilities.\n",
      "\n",
      "Data Requirements:\n",
      "- Market price data and historical trading volumes\n",
      "- Order book data including bid-ask spreads\n",
      "- Agent performance metrics and decision rationales\n",
      "- Dividend payment structures and interest rates\n",
      "- Market state information for real-time decision-making\n"
     ]
    }
   ],
   "source": [
    "# Run the summary test\n",
    "summary = await test_paper_summary('2504.10789v1')\n",
    "\n",
    "# Display certain sections in more detail\n",
    "if summary:\n",
    "    print(\"\\nMethods:\")\n",
    "    for method in summary.get(\"methods\", []):\n",
    "        print(f\"- {method}\")\n",
    "        \n",
    "    print(\"\\nTrading Applications:\")\n",
    "    for app in summary.get(\"trading_applications\", []):\n",
    "        print(f\"- {app}\")\n",
    "        \n",
    "    print(\"\\nData Requirements:\")\n",
    "    for req in summary.get(\"data_requirements\", []):\n",
    "        print(f\"- {req}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Testing Paper Full Text Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_paper_text(paper_id):\n",
    "    \"\"\"Test retrieving paper full text\"\"\"\n",
    "    if not paper_id:\n",
    "        print(\"No paper ID provided\")\n",
    "        return None\n",
    "        \n",
    "    print(f\"Testing paper text endpoint for paper ID: {paper_id}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    async with httpx.AsyncClient(timeout=60.0) as client:\n",
    "        response = await client.get(f\"{API_BASE_URL}/summarize/text/{paper_id}\")\n",
    "        \n",
    "        print(f\"Status code: {response.status_code}\")\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"Response time: {elapsed:.2f} seconds\")\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            paper_text = response.json()\n",
    "            text_length = len(paper_text.get(\"full_text\", \"\"))\n",
    "            print(f\"Retrieved {text_length} characters of text\")\n",
    "            \n",
    "            # Show the first 500 characters of text as preview\n",
    "            print(\"\\nText preview:\")\n",
    "            print(paper_text.get(\"full_text\", \"\")[:500] + \"...\")\n",
    "            \n",
    "            # Show available sections if any\n",
    "            sections = paper_text.get(\"sections\", {})\n",
    "            if sections:\n",
    "                print(f\"\\nIdentified {len(sections)} sections:\")\n",
    "                for section, content in sections.items():\n",
    "                    print(f\"- {section}: {len(content)} characters\")\n",
    "            \n",
    "            return paper_text\n",
    "        else:\n",
    "            print(f\"Error retrieving paper text: {response.text}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing paper text endpoint for paper ID: 2504.10789v1\n",
      "Status code: 200\n",
      "Response time: 0.85 seconds\n",
      "Retrieved 76480 characters of text\n",
      "\n",
      "Text preview:\n",
      "Can Large Language Models Trade? Testing Financial\n",
      "\n",
      "Theories with LLM Agents in Market Simulations\n",
      "\n",
      "Alejandro Lopez-Lira∗\n",
      "First Version: November 29, 2024; Current Version: April 16, 2025\n",
      "\n",
      "Abstract\n",
      "\n",
      "This paper presents a realistic simulated stock market where large language models\n",
      "\n",
      "(LLMs) act as heterogeneous competing trading agents. The open-source framework\n",
      "\n",
      "incorporates a persistent order book with market and limit orders, partial fills, div-\n",
      "\n",
      "idends, and equilibrium clearing alongside agent...\n"
     ]
    }
   ],
   "source": [
    "paper_text = await test_paper_text('2504.10789v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Testing Q&A Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_qa(paper_id, question):\n",
    "    \"\"\"Test asking a question about a paper\"\"\"\n",
    "    if not paper_id:\n",
    "        print(\"No paper ID provided\")\n",
    "        return None\n",
    "        \n",
    "    print(f\"Testing QA endpoint with paper ID: {paper_id}\")\n",
    "    print(f\"Question: {question}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    async with httpx.AsyncClient(timeout=60.0) as client:  # Longer timeout for LLM processing\n",
    "        response = await client.post(\n",
    "            f\"{API_BASE_URL}/qa/\",\n",
    "            json={\"question\": question, \"paper_ids\": [paper_id]}\n",
    "        )\n",
    "        \n",
    "        print(f\"Status code: {response.status_code}\")\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"Response time: {elapsed:.2f} seconds\")\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            qa_result = response.json()\n",
    "            print(f\"Confidence: {qa_result.get('confidence', 0)}\")\n",
    "            print(f\"\\nAnswer: {qa_result.get('answer', '')}\")\n",
    "            \n",
    "            # Display suggested follow-up questions if available\n",
    "            suggestions = qa_result.get('suggestions', [])\n",
    "            if suggestions:\n",
    "                print(\"\\nSuggested follow-up questions:\")\n",
    "                for suggestion in suggestions:\n",
    "                    print(f\"- {suggestion}\")\n",
    "                    \n",
    "            return qa_result\n",
    "        else:\n",
    "            print(f\"Error getting answer: {response.text}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Q&A test\n",
    "qa_result = await test_qa(\n",
    "    paper_id, \n",
    "    \"What are the main trading applications of this research and how difficult would it be to implement?\"\n",
    ")\n",
    "\n",
    "# Display full Q&A result\n",
    "if qa_result:\n",
    "    print(\"\\nFull Q&A result:\")\n",
    "    display_json(qa_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Testing Strategy Generation Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_strategy(paper_id, market=\"equities\", timeframe=\"daily\", risk_profile=\"moderate\"):\n",
    "    \"\"\"Test generating a trading strategy\"\"\"\n",
    "    if not paper_id:\n",
    "        print(\"No paper ID provided\")\n",
    "        return None\n",
    "        \n",
    "    print(f\"Testing strategy endpoint for paper ID: {paper_id}\")\n",
    "    print(f\"Market: {market}, Timeframe: {timeframe}, Risk Profile: {risk_profile}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    async with httpx.AsyncClient(timeout=120.0) as client:  # Longer timeout for strategy generation\n",
    "        response = await client.post(\n",
    "            f\"{API_BASE_URL}/strategy/\",\n",
    "            json={\n",
    "                \"paper_ids\": [paper_id],\n",
    "                \"market\": market,\n",
    "                \"timeframe\": timeframe,\n",
    "                \"risk_profile\": risk_profile,\n",
    "                \"additional_context\": \"Focus on practical implementation with clear entry/exit rules\"\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        print(f\"Status code: {response.status_code}\")\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"Response time: {elapsed:.2f} seconds\")\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            strategy = response.json()\n",
    "            print(f\"Strategy name: {strategy.get('strategy_name', 'N/A')}\")\n",
    "            print(f\"Code length: {len(strategy.get('python_code', ''))} characters\")\n",
    "            \n",
    "            # Preview the description\n",
    "            description = strategy.get('description', '')\n",
    "            print(f\"\\nDescription: {description[:200]}...\")\n",
    "            \n",
    "            return strategy\n",
    "        else:\n",
    "            print(f\"Error generating strategy: {response.text}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the strategy generation test\n",
    "strategy = await test_strategy(paper_id)\n",
    "\n",
    "# Display the generated Python code\n",
    "if strategy and 'python_code' in strategy:\n",
    "    print(\"\\nGenerated Python Code:\")\n",
    "    print(\"```python\")\n",
    "    print(strategy['python_code'])\n",
    "    print(\"```\")\n",
    "    \n",
    "    print(\"\\nUsage Notes:\")\n",
    "    print(strategy.get('usage_notes', 'Not available'))\n",
    "    \n",
    "    print(\"\\nLimitations:\")\n",
    "    print(strategy.get('limitations', 'Not available'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Testing Streaming Strategy Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_strategy_streaming(paper_id, market=\"crypto\", timeframe=\"hourly\", risk_profile=\"aggressive\"):\n",
    "    \"\"\"Test streaming strategy generation\"\"\"\n",
    "    if not paper_id:\n",
    "        print(\"No paper ID provided\")\n",
    "        return\n",
    "        \n",
    "    print(f\"Testing streaming strategy endpoint for paper ID: {paper_id}\")\n",
    "    print(f\"Market: {market}, Timeframe: {timeframe}, Risk Profile: {risk_profile}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # This is a simplified streaming test - in a real application you would\n",
    "    # process the streaming response as it comes in\n",
    "    async with httpx.AsyncClient(timeout=120.0) as client:\n",
    "        with client.stream(\n",
    "            \"POST\",\n",
    "            f\"{API_BASE_URL}/strategy/stream\",\n",
    "            json={\n",
    "                \"paper_ids\": [paper_id],\n",
    "                \"market\": market,\n",
    "                \"timeframe\": timeframe,\n",
    "                \"risk_profile\": risk_profile,\n",
    "                \"additional_context\": \"Focus on high-frequency trading aspects if applicable\"\n",
    "            }\n",
    "        ) as response:\n",
    "            print(f\"Status code: {response.status_code}\")\n",
    "            if response.status_code == 200:\n",
    "                print(\"Receiving streaming response...\")\n",
    "                # Just print the first few chunks to demonstrate streaming\n",
    "                chunks_received = 0\n",
    "                async for chunk in response.aiter_text():\n",
    "                    chunks_received += 1\n",
    "                    # Print first 3 chunks and then just show progress\n",
    "                    if chunks_received <= 3:\n",
    "                        print(f\"\\nChunk {chunks_received}:\\n{chunk}\")\n",
    "                    if chunks_received % 10 == 0:\n",
    "                        print(f\"Received {chunks_received} chunks...\")\n",
    "                        \n",
    "                elapsed = time.time() - start_time\n",
    "                print(f\"\\nStreaming completed in {elapsed:.2f} seconds\")\n",
    "                print(f\"Received {chunks_received} total chunks\")\n",
    "            else:\n",
    "                print(f\"Error with streaming: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the streaming strategy test\n",
    "# Note: This is optional and may not work if streaming isn't implemented\n",
    "await test_strategy_streaming(paper_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Tests Complete\n",
    "\n",
    "The notebook has finished testing all major endpoints of the ResearchTrader API."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
