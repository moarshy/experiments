{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResearchTrader API Testing\n",
    "\n",
    "This notebook tests each endpoint of the ResearchTrader API to ensure everything is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing API running at: http://127.0.0.1:8000\n"
     ]
    }
   ],
   "source": [
    "import httpx\n",
    "import asyncio\n",
    "import json\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "# API configuration\n",
    "# !!! Make sure this matches your running backend API URL !!!\n",
    "API_BASE_URL = \"http://127.0.0.1:8000\"\n",
    "\n",
    "# --- Global variables to store results between steps ---\n",
    "# Stores the ID of the paper found in the search step\n",
    "paper_id_to_test = None\n",
    "# Stores the full paper details once retrieved after processing\n",
    "detailed_paper = None\n",
    "# ---\n",
    "\n",
    "print(f\"Testing API running at: {API_BASE_URL}\")\n",
    "\n",
    "# Helper for pretty printing\n",
    "def print_json(data, title=\"Response Data\"):\n",
    "    print(f\"\\n--- {title} ---\")\n",
    "    if data:\n",
    "        try:\n",
    "            print(json.dumps(data, indent=2))\n",
    "        except TypeError: # Handle potential non-serializable types like datetime\n",
    "            pprint(data)\n",
    "    else:\n",
    "        print(\"(No data)\")\n",
    "    print(\"--- End Response ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test POST /papers/ (Search & Process Trigger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing POST /papers/ ---\n",
      "Query: 'transformer finance forecasting', Max Results: 3\n",
      "Status code: 200\n",
      "Response time: 2.53 seconds\n",
      "Found 3 papers. Background processing triggered.\n",
      "Using Paper ID for subsequent tests: 2504.13529v1\n",
      "Title: Risk-aware black-box portfolio construction using Bayesian optimization with adaptive weighted Lagrangian estimator\n",
      "Initial Summary (if cached): Not available yet\n",
      "\n",
      "Pausing briefly for background processing to potentially start...\n",
      "\n",
      "--- Search Results Summary ---\n",
      "[\n",
      "  {\n",
      "    \"paper_id\": \"2504.13529v1\",\n",
      "    \"title\": \"Risk-aware black-box portfolio construction using Bayesian optimization with adaptive weighted Lagrangian estimator\",\n",
      "    \"authors\": [\n",
      "      \"Zinuo You\",\n",
      "      \"John Cartlidge\",\n",
      "      \"Karen Elliott\",\n",
      "      \"Menghan Ge\",\n",
      "      \"Daniel Gold\"\n",
      "    ],\n",
      "    \"abstract\": \"Existing portfolio management approaches are often black-box models due to\\nsafety and commercial issues in the industry. However, their performance can\\nvary considerably whenever market conditions or internal trading strategies\\nchange. Furthermore, evaluating these non-transparent systems is expensive,\\nwhere certain budgets limit observations of the systems. Therefore, optimizing\\nperformance while controlling the potential risk of these financial systems has\\nbecome a critical challenge. This work presents a novel Bayesian optimization\\nframework to optimize black-box portfolio management models under limited\\nobservations. In conventional Bayesian optimization settings, the objective\\nfunction is to maximize the expectation of performance metrics. However, simply\\nmaximizing performance expectations leads to erratic optimization trajectories,\\nwhich exacerbate risk accumulation in portfolio management. Meanwhile, this can\\nlead to misalignment between the target distribution and the actual\\ndistribution of the black-box model. To mitigate this problem, we propose an\\nadaptive weight Lagrangian estimator considering dual objective, which\\nincorporates maximizing model performance and minimizing variance of model\\nobservations. Extensive experiments demonstrate the superiority of our approach\\nover five backtest settings with three black-box stock portfolio management\\nmodels. Ablation studies further verify the effectiveness of the proposed\\nestimator.\",\n",
      "    \"published_date\": \"2025-04-18T07:40:24Z\",\n",
      "    \"pdf_url\": \"http://arxiv.org/pdf/2504.13529v1\",\n",
      "    \"source_url\": \"http://arxiv.org/abs/2504.13529v1\",\n",
      "    \"tags\": [\n",
      "      \"eess.SY\",\n",
      "      \"cs.LG\",\n",
      "      \"cs.SY\",\n",
      "      \"q-fin.CP\",\n",
      "      \"q-fin.PM\"\n",
      "    ],\n",
      "    \"structured_summary\": null,\n",
      "    \"comprehensive_summary\": null\n",
      "  },\n",
      "  {\n",
      "    \"paper_id\": \"2504.13522v1\",\n",
      "    \"title\": \"Cross-Modal Temporal Fusion for Financial Market Forecasting\",\n",
      "    \"authors\": [\n",
      "      \"Yunhua Pei\",\n",
      "      \"John Cartlidge\",\n",
      "      \"Anandadeep Mandal\",\n",
      "      \"Daniel Gold\",\n",
      "      \"Enrique Marcilio\",\n",
      "      \"Riccardo Mazzon\"\n",
      "    ],\n",
      "    \"abstract\": \"Accurate financial market forecasting requires diverse data sources,\\nincluding historical price trends, macroeconomic indicators, and financial\\nnews, each contributing unique predictive signals. However, existing methods\\noften process these modalities independently or fail to effectively model their\\ninteractions. In this paper, we introduce Cross-Modal Temporal Fusion (CMTF), a\\nnovel transformer-based framework that integrates heterogeneous financial data\\nto improve predictive accuracy. Our approach employs attention mechanisms to\\ndynamically weight the contribution of different modalities, along with a\\nspecialized tensor interpretation module for feature extraction. To facilitate\\nrapid model iteration in industry applications, we incorporate a mature\\nauto-training scheme that streamlines optimization. When applied to real-world\\nfinancial datasets, CMTF demonstrates improvements over baseline models in\\nforecasting stock price movements and provides a scalable and effective\\nsolution for cross-modal integration in financial market prediction.\",\n",
      "    \"published_date\": \"2025-04-18T07:20:18Z\",\n",
      "    \"pdf_url\": \"http://arxiv.org/pdf/2504.13522v1\",\n",
      "    \"source_url\": \"http://arxiv.org/abs/2504.13522v1\",\n",
      "    \"tags\": [\n",
      "      \"cs.LG\",\n",
      "      \"cs.NE\",\n",
      "      \"q-fin.CP\"\n",
      "    ],\n",
      "    \"structured_summary\": null,\n",
      "    \"comprehensive_summary\": null\n",
      "  },\n",
      "  {\n",
      "    \"paper_id\": \"2504.13521v2\",\n",
      "    \"title\": \"Deep Learning Models Meet Financial Data Modalities\",\n",
      "    \"authors\": [\n",
      "      \"Kasymkhan Khubiev\",\n",
      "      \"Mikhail Semenov\"\n",
      "    ],\n",
      "    \"abstract\": \"Algorithmic trading relies on extracting meaningful signals from diverse\\nfinancial data sources, including candlestick charts, order statistics on put\\nand canceled orders, traded volume data, limit order books, and news flow.\\nWhile deep learning has demonstrated remarkable success in processing\\nunstructured data and has significantly advanced natural language processing,\\nits application to structured financial data remains an ongoing challenge. This\\nstudy investigates the integration of deep learning models with financial data\\nmodalities, aiming to enhance predictive performance in trading strategies and\\nportfolio optimization. We present a novel approach to incorporating limit\\norder book analysis into algorithmic trading by developing embedding techniques\\nand treating sequential limit order book snapshots as distinct input channels\\nin an image-based representation. Our methodology for processing limit order\\nbook data achieves state-of-the-art performance in high-frequency trading\\nalgorithms, underscoring the effectiveness of deep learning in financial\\napplications.\",\n",
      "    \"published_date\": \"2025-04-18T07:19:44Z\",\n",
      "    \"pdf_url\": \"http://arxiv.org/pdf/2504.13521v2\",\n",
      "    \"source_url\": \"http://arxiv.org/abs/2504.13521v2\",\n",
      "    \"tags\": [\n",
      "      \"cs.LG\",\n",
      "      \"cs.AI\",\n",
      "      \"cs.CE\",\n",
      "      \"q-fin.ST\"\n",
      "    ],\n",
      "    \"structured_summary\": null,\n",
      "    \"comprehensive_summary\": null\n",
      "  }\n",
      "]\n",
      "--- End Response ---\n"
     ]
    }
   ],
   "source": [
    "async def test_search_and_process(query=\"transformer finance forecasting\", max_results=3):\n",
    "    \"\"\"Tests the search endpoint (POST /papers/) which triggers background processing.\"\"\"\n",
    "    global paper_id_to_test # Allow modifying the global variable\n",
    "    print(f\"\\n--- Testing POST /papers/ ---\")\n",
    "    print(f\"Query: '{query}', Max Results: {max_results}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    payload = {\"query\": query, \"max_results\": max_results, \"force_reprocess\": False} # Set force_reprocess if needed\n",
    "    search_results_summary = None\n",
    "\n",
    "    async with httpx.AsyncClient(timeout=60.0) as client:\n",
    "        try:\n",
    "            response = await client.post(f\"{API_BASE_URL}/papers/\", json=payload)\n",
    "            response.raise_for_status() # Raise exception for bad status codes\n",
    "\n",
    "            print(f\"Status code: {response.status_code}\")\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"Response time: {elapsed:.2f} seconds\")\n",
    "\n",
    "            response_data = response.json()\n",
    "            search_results_summary = response_data # Store for display\n",
    "\n",
    "            # Response is List[PaperSummaryResponse]\n",
    "            if isinstance(response_data, list) and len(response_data) > 0:\n",
    "                print(f\"Found {len(response_data)} papers. Background processing triggered.\")\n",
    "                first_paper = response_data[0]\n",
    "                paper_id_to_test = first_paper.get(\"paper_id\") # Store the ID\n",
    "                print(f\"Using Paper ID for subsequent tests: {paper_id_to_test}\")\n",
    "                print(f\"Title: {first_paper.get('title')}\")\n",
    "                print(f\"Initial Summary (if cached): {first_paper.get('summary', 'Not available yet')}\")\n",
    "                print(\"\\nPausing briefly for background processing to potentially start...\")\n",
    "                await asyncio.sleep(3) # Give backend a few seconds to kick off tasks\n",
    "            elif isinstance(response_data, list) and len(response_data) == 0:\n",
    "                print(\"Search returned successfully, but no papers found.\")\n",
    "                paper_id_to_test = None\n",
    "            else:\n",
    "                print(\"No papers found or unexpected response structure\")\n",
    "                paper_id_to_test = None\n",
    "\n",
    "        except httpx.HTTPStatusError as e:\n",
    "            print(f\"HTTP Error: {e.response.status_code}\")\n",
    "            try:\n",
    "                print(f\"Detail: {e.response.json()}\")\n",
    "            except:\n",
    "                print(f\"Body: {e.response.text}\")\n",
    "            paper_id_to_test = None\n",
    "        except httpx.RequestError as e:\n",
    "            print(f\"Request Error: Could not connect to API at {API_BASE_URL}. Is it running?\")\n",
    "            print(f\"Details: {e}\")\n",
    "            paper_id_to_test = None\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {type(e).__name__}: {e}\")\n",
    "            paper_id_to_test = None\n",
    "\n",
    "    print_json(search_results_summary, title=\"Search Results Summary\")\n",
    "\n",
    "await test_search_and_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test GET /papers/{id} (Get Details - Waits for Processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing GET /papers/2504.13529v1 (with retries) ---\n",
      "\n",
      "Attempt 1/15 to fetch details for 2504.13529v1\n",
      "Status code: 200, Response time: 0.00 seconds\n",
      ">>> Paper details retrieved successfully with content!\n",
      "Title: Risk-aware black-box portfolio construction using Bayesian optimization with adaptive weighted Lagrangian estimator\n",
      "Objective: To optimize black-box portfolio management models using a novel Bayesian optimization framework that balances performance and risk.\n",
      "Full Text: Available\n"
     ]
    }
   ],
   "source": [
    "async def test_get_paper_details(paper_id, max_retries=15, delay=15):\n",
    "    \"\"\"Tests getting full paper details (GET /papers/{id}), retrying until processed.\"\"\"\n",
    "    global detailed_paper # Allow modifying the global variable\n",
    "    print(f\"\\n--- Testing GET /papers/{paper_id} (with retries) ---\")\n",
    "    if not paper_id:\n",
    "        print(\"No paper ID provided from search step. Skipping.\")\n",
    "        return\n",
    "\n",
    "    async with httpx.AsyncClient(timeout=45.0) as client:\n",
    "        last_response_data = None\n",
    "        for attempt in range(max_retries):\n",
    "            print(f\"\\nAttempt {attempt + 1}/{max_retries} to fetch details for {paper_id}\")\n",
    "            start_time = time.time()\n",
    "            try:\n",
    "                # Add force_reprocess=True here if you want to test reprocessing\n",
    "                response = await client.get(f\"{API_BASE_URL}/papers/{paper_id}\") #, params={\"force_reprocess\": True})\n",
    "                response.raise_for_status()\n",
    "\n",
    "                elapsed = time.time() - start_time\n",
    "                print(f\"Status code: {response.status_code}, Response time: {elapsed:.2f} seconds\")\n",
    "\n",
    "                paper_data = response.json()\n",
    "                last_response_data = paper_data # Store last successful response\n",
    "\n",
    "                # Check if content (summaries) are populated\n",
    "                has_content = False\n",
    "                if paper_data.get(\"content\"):\n",
    "                    # Check for both summaries as a sign processing is likely complete\n",
    "                    if paper_data[\"content\"].get(\"comprehensive_summary\") and paper_data[\"content\"].get(\"structured_summary\"):\n",
    "                        has_content = True\n",
    "\n",
    "                if has_content:\n",
    "                    print(\">>> Paper details retrieved successfully with content!\")\n",
    "                    detailed_paper = paper_data # Store details\n",
    "                    # Display some key info\n",
    "                    print(f\"Title: {paper_data.get('metadata', {}).get('title', 'N/A')}\")\n",
    "                    print(f\"Objective: {paper_data.get('content', {}).get('structured_summary', {}).get('objective', 'N/A')}\")\n",
    "                    ft_status = \"Available\" if paper_data.get('content', {}).get('full_text') else 'Not available/extracted'\n",
    "                    print(f\"Full Text: {ft_status}\")\n",
    "                    return # Exit loop on success\n",
    "                else:\n",
    "                    print(\"Paper found, but content (summaries) not yet available. Waiting...\")\n",
    "\n",
    "            except httpx.HTTPStatusError as e:\n",
    "                if e.response.status_code == 404:\n",
    "                    print(\"Paper not found (404). Might not exist or processing failed severely.\")\n",
    "                    return # Stop retrying if not found\n",
    "                else:\n",
    "                    print(f\"HTTP Error fetching paper: {e.response.status_code}\")\n",
    "                    try: print(f\"Detail: {e.response.json()}\")\n",
    "                    except: print(f\"Body: {e.response.text}\")\n",
    "                    # Decide whether to retry on other errors (currently retries)\n",
    "\n",
    "            except httpx.RequestError as e:\n",
    "                print(f\"Request Error fetching paper: {e}\")\n",
    "                # Decide whether to retry (currently retries)\n",
    "\n",
    "            except json.JSONDecodeError as e:\n",
    "                 print(f\"JSON Decode Error fetching paper: {e}. Response text: {response.text}\")\n",
    "                 # Decide whether to retry (currently retries)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"An unexpected error occurred: {type(e).__name__}: {e}\")\n",
    "                # Decide whether to retry (currently retries)\n",
    "\n",
    "            # Wait before retrying if not successful and not a fatal error\n",
    "            if attempt < max_retries - 1:\n",
    "                print(f\"Waiting {delay} seconds before next attempt...\")\n",
    "                await asyncio.sleep(delay)\n",
    "            else:\n",
    "                print(f\">>> Max retries ({max_retries}) reached. Paper content might not be available.\")\n",
    "                if last_response_data:\n",
    "                     print(\"Storing last successful response data (potentially incomplete).\")\n",
    "                     detailed_paper = last_response_data # Store potentially incomplete data\n",
    "                return # Exit loop after max retries\n",
    "\n",
    "await test_get_paper_details(paper_id_to_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test GET /papers/ (List Cached Papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing GET /papers/ ---\n",
      "Status code: 200\n",
      "Response time: 0.01 seconds\n",
      "Found 3 papers currently in cache.\n",
      "\n",
      "--- List of Cached Papers (Summary View) ---\n",
      "[\n",
      "  {\n",
      "    \"paper_id\": \"2504.13529v1\",\n",
      "    \"title\": \"Risk-aware black-box portfolio construction using Bayesian optimization with adaptive weighted Lagrangian estimator\",\n",
      "    \"authors\": [\n",
      "      \"Zinuo You\",\n",
      "      \"John Cartlidge\",\n",
      "      \"Karen Elliott\",\n",
      "      \"Menghan Ge\",\n",
      "      \"Daniel Gold\"\n",
      "    ],\n",
      "    \"abstract\": \"Existing portfolio management approaches are often black-box models due to\\nsafety and commercial issues in the industry. However, their performance can\\nvary considerably whenever market conditions or internal trading strategies\\nchange. Furthermore, evaluating these non-transparent systems is expensive,\\nwhere certain budgets limit observations of the systems. Therefore, optimizing\\nperformance while controlling the potential risk of these financial systems has\\nbecome a critical challenge. This work presents a novel Bayesian optimization\\nframework to optimize black-box portfolio management models under limited\\nobservations. In conventional Bayesian optimization settings, the objective\\nfunction is to maximize the expectation of performance metrics. However, simply\\nmaximizing performance expectations leads to erratic optimization trajectories,\\nwhich exacerbate risk accumulation in portfolio management. Meanwhile, this can\\nlead to misalignment between the target distribution and the actual\\ndistribution of the black-box model. To mitigate this problem, we propose an\\nadaptive weight Lagrangian estimator considering dual objective, which\\nincorporates maximizing model performance and minimizing variance of model\\nobservations. Extensive experiments demonstrate the superiority of our approach\\nover five backtest settings with three black-box stock portfolio management\\nmodels. Ablation studies further verify the effectiveness of the proposed\\nestimator.\",\n",
      "    \"published_date\": \"2025-04-18T07:40:24Z\",\n",
      "    \"pdf_url\": \"http://arxiv.org/pdf/2504.13529v1\",\n",
      "    \"source_url\": \"http://arxiv.org/abs/2504.13529v1\",\n",
      "    \"tags\": [\n",
      "      \"eess.SY\",\n",
      "      \"cs.LG\",\n",
      "      \"cs.SY\",\n",
      "      \"q-fin.CP\",\n",
      "      \"q-fin.PM\"\n",
      "    ],\n",
      "    \"structured_summary\": null,\n",
      "    \"comprehensive_summary\": null\n",
      "  },\n",
      "  {\n",
      "    \"paper_id\": \"2504.13521v2\",\n",
      "    \"title\": \"Deep Learning Models Meet Financial Data Modalities\",\n",
      "    \"authors\": [\n",
      "      \"Kasymkhan Khubiev\",\n",
      "      \"Mikhail Semenov\"\n",
      "    ],\n",
      "    \"abstract\": \"Algorithmic trading relies on extracting meaningful signals from diverse\\nfinancial data sources, including candlestick charts, order statistics on put\\nand canceled orders, traded volume data, limit order books, and news flow.\\nWhile deep learning has demonstrated remarkable success in processing\\nunstructured data and has significantly advanced natural language processing,\\nits application to structured financial data remains an ongoing challenge. This\\nstudy investigates the integration of deep learning models with financial data\\nmodalities, aiming to enhance predictive performance in trading strategies and\\nportfolio optimization. We present a novel approach to incorporating limit\\norder book analysis into algorithmic trading by developing embedding techniques\\nand treating sequential limit order book snapshots as distinct input channels\\nin an image-based representation. Our methodology for processing limit order\\nbook data achieves state-of-the-art performance in high-frequency trading\\nalgorithms, underscoring the effectiveness of deep learning in financial\\napplications.\",\n",
      "    \"published_date\": \"2025-04-18T07:19:44Z\",\n",
      "    \"pdf_url\": \"http://arxiv.org/pdf/2504.13521v2\",\n",
      "    \"source_url\": \"http://arxiv.org/abs/2504.13521v2\",\n",
      "    \"tags\": [\n",
      "      \"cs.LG\",\n",
      "      \"cs.AI\",\n",
      "      \"cs.CE\",\n",
      "      \"q-fin.ST\"\n",
      "    ],\n",
      "    \"structured_summary\": null,\n",
      "    \"comprehensive_summary\": null\n",
      "  },\n",
      "  {\n",
      "    \"paper_id\": \"2504.13522v1\",\n",
      "    \"title\": \"Cross-Modal Temporal Fusion for Financial Market Forecasting\",\n",
      "    \"authors\": [\n",
      "      \"Yunhua Pei\",\n",
      "      \"John Cartlidge\",\n",
      "      \"Anandadeep Mandal\",\n",
      "      \"Daniel Gold\",\n",
      "      \"Enrique Marcilio\",\n",
      "      \"Riccardo Mazzon\"\n",
      "    ],\n",
      "    \"abstract\": \"Accurate financial market forecasting requires diverse data sources,\\nincluding historical price trends, macroeconomic indicators, and financial\\nnews, each contributing unique predictive signals. However, existing methods\\noften process these modalities independently or fail to effectively model their\\ninteractions. In this paper, we introduce Cross-Modal Temporal Fusion (CMTF), a\\nnovel transformer-based framework that integrates heterogeneous financial data\\nto improve predictive accuracy. Our approach employs attention mechanisms to\\ndynamically weight the contribution of different modalities, along with a\\nspecialized tensor interpretation module for feature extraction. To facilitate\\nrapid model iteration in industry applications, we incorporate a mature\\nauto-training scheme that streamlines optimization. When applied to real-world\\nfinancial datasets, CMTF demonstrates improvements over baseline models in\\nforecasting stock price movements and provides a scalable and effective\\nsolution for cross-modal integration in financial market prediction.\",\n",
      "    \"published_date\": \"2025-04-18T07:20:18Z\",\n",
      "    \"pdf_url\": \"http://arxiv.org/pdf/2504.13522v1\",\n",
      "    \"source_url\": \"http://arxiv.org/abs/2504.13522v1\",\n",
      "    \"tags\": [\n",
      "      \"cs.LG\",\n",
      "      \"cs.NE\",\n",
      "      \"q-fin.CP\"\n",
      "    ],\n",
      "    \"structured_summary\": null,\n",
      "    \"comprehensive_summary\": null\n",
      "  }\n",
      "]\n",
      "--- End Response ---\n"
     ]
    }
   ],
   "source": [
    "async def test_list_cached_papers():\n",
    "    \"\"\"Tests listing all cached papers (GET /papers/)\"\"\"\n",
    "    print(f\"\\n--- Testing GET /papers/ ---\")\n",
    "    start_time = time.time()\n",
    "    cached_papers_list = None\n",
    "\n",
    "    async with httpx.AsyncClient(timeout=30.0) as client:\n",
    "        try:\n",
    "            response = await client.get(f\"{API_BASE_URL}/papers/\")\n",
    "            response.raise_for_status()\n",
    "\n",
    "            print(f\"Status code: {response.status_code}\")\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"Response time: {elapsed:.2f} seconds\")\n",
    "\n",
    "            cached_papers = response.json()\n",
    "\n",
    "            if isinstance(cached_papers, list):\n",
    "                print(f\"Found {len(cached_papers)} papers currently in cache.\")\n",
    "                cached_papers_list = cached_papers\n",
    "            else:\n",
    "                print(\"Unexpected response format.\")\n",
    "\n",
    "        except httpx.HTTPStatusError as e:\n",
    "            print(f\"HTTP Error: {e.response.status_code}\")\n",
    "            try: print(f\"Detail: {e.response.json()}\")\n",
    "            except: print(f\"Body: {e.response.text}\")\n",
    "        except httpx.RequestError as e:\n",
    "            print(f\"Request Error: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {type(e).__name__}: {e}\")\n",
    "\n",
    "    print_json(cached_papers_list, title=\"List of Cached Papers (Summary View)\")\n",
    "\n",
    "\n",
    "await test_list_cached_papers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test POST /qa/ (Q&A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing POST /qa/ ---\n",
      "Using Paper ID: 2504.13529v1\n",
      "Question: What is the main objective of this paper and what methods were used?\n",
      "Status code: 200\n",
      "Response time: 2.95 seconds\n",
      "Context Paper IDs Used: ['2504.13529v1']\n",
      "\n",
      "Answer:\n",
      "The main objective of the paper is to optimize black-box portfolio management models using a novel Bayesian optimization framework that balances performance and risk. The methods used include:\n",
      "\n",
      "- An adaptive weighted Lagrangian estimator for dual objective optimization.\n",
      "- Bayesian optimization with importance sampling to guide the surrogate model.\n",
      "- Three surrogate models: Gaussian Processes (GP), Tree-structured Parzen Estimators (TPE), and Bayesian Neural Networks (BNN).\n",
      "- Acquisition functions such as Expected Improvement (EI), Upper Confidence Bound (UCB), and Probability of Improvement (PI) [ID: 2504.13529v1].\n",
      "\n",
      "--- Q&A Response ---\n",
      "{\n",
      "  \"question\": \"What is the main objective of this paper and what methods were used?\",\n",
      "  \"answer\": \"The main objective of the paper is to optimize black-box portfolio management models using a novel Bayesian optimization framework that balances performance and risk. The methods used include:\\n\\n- An adaptive weighted Lagrangian estimator for dual objective optimization.\\n- Bayesian optimization with importance sampling to guide the surrogate model.\\n- Three surrogate models: Gaussian Processes (GP), Tree-structured Parzen Estimators (TPE), and Bayesian Neural Networks (BNN).\\n- Acquisition functions such as Expected Improvement (EI), Upper Confidence Bound (UCB), and Probability of Improvement (PI) [ID: 2504.13529v1].\",\n",
      "  \"context_paper_ids\": [\n",
      "    \"2504.13529v1\"\n",
      "  ]\n",
      "}\n",
      "--- End Response ---\n"
     ]
    }
   ],
   "source": [
    "async def test_qa(paper_id, question):\n",
    "    \"\"\"Tests asking a question about a paper (POST /qa/)\"\"\"\n",
    "    print(f\"\\n--- Testing POST /qa/ ---\")\n",
    "    if not paper_id:\n",
    "        print(\"No paper ID available for Q&A test. Skipping.\")\n",
    "        return\n",
    "    # Check if detailed_paper was successfully populated in the get_details step\n",
    "    if not detailed_paper or not detailed_paper.get(\"content\"):\n",
    "         print(\"Detailed paper info (with content) not retrieved in previous step. Skipping Q&A.\")\n",
    "         print(\"(This might happen if get_details timed out or failed)\")\n",
    "         return\n",
    "\n",
    "    print(f\"Using Paper ID: {paper_id}\")\n",
    "    print(f\"Question: {question}\")\n",
    "    start_time = time.time()\n",
    "    qa_result_data = None\n",
    "\n",
    "    payload = {\"question\": question, \"paper_ids\": [paper_id]}\n",
    "\n",
    "    async with httpx.AsyncClient(timeout=120.0) as client: # Longer timeout for LLM\n",
    "        try:\n",
    "            response = await client.post(f\"{API_BASE_URL}/qa/\", json=payload)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            print(f\"Status code: {response.status_code}\")\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"Response time: {elapsed:.2f} seconds\")\n",
    "\n",
    "            qa_result = response.json() # Response is QAResponse model\n",
    "            qa_result_data = qa_result\n",
    "            print(f\"Context Paper IDs Used: {qa_result.get('context_paper_ids')}\")\n",
    "            print(f\"\\nAnswer:\\n{qa_result.get('answer', 'N/A')}\")\n",
    "\n",
    "        except httpx.HTTPStatusError as e:\n",
    "            print(f\"HTTP Error: {e.response.status_code}\")\n",
    "            try:\n",
    "                 err_detail = e.response.json().get('detail', e.response.text)\n",
    "                 print(f\"Detail: {err_detail}\")\n",
    "                 if e.response.status_code == 404 and \"not found in the cache\" in err_detail:\n",
    "                     print(\"(This confirms the check for cached papers is working)\")\n",
    "            except: print(f\"Body: {e.response.text}\")\n",
    "        except httpx.RequestError as e:\n",
    "            print(f\"Request Error: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {type(e).__name__}: {e}\")\n",
    "\n",
    "    print_json(qa_result_data, title=\"Q&A Response\")\n",
    "\n",
    "question_to_ask = \"What is the main objective of this paper and what methods were used?\"\n",
    "await test_qa(paper_id_to_test, question_to_ask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test POST /strategy/ (Strategy Generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing POST /strategy/ ---\n",
      "Using Paper ID: 2504.13529v1\n",
      "Prompt: Generate a simple strategy based on the core concept mentioned in the abstract or objective of paper 2504.13529v1. Keep it high level.\n",
      "Status code: 200\n",
      "Response time: 15.37 seconds\n",
      "\n",
      "Generation Notes: Structured strategy outline generated successfully.\n",
      "Context Paper IDs Used: ['2504.13529v1']\n",
      "\n",
      "--- Strategy Description ---\n",
      "This strategy utilizes a Bayesian optimization framework to construct a portfolio that balances maximizing returns and minimizing risk. The core logic is based on the adaptive weighted Lagrangian estimator proposed in the paper [ID: 2504.13529v1], which optimizes portfolio performance while controlling for variance in returns. By leveraging surrogate models such as Gaussian Processes (GP) and Tree-structured Parzen Estimators (TPE), the strategy dynamically adjusts to market conditions, ensuring that the portfolio adapts to changing risk profiles while aiming for high Sharpe ratios.\n",
      "\n",
      "--- Pseudocode / Logic ---\n",
      "['1. Initialize portfolio with a set of assets.', '2. Define objective function to maximize expected returns and minimize variance.', '3. Set up Bayesian optimization framework with chosen surrogate model (GP or TPE).', '4. For each iteration:', '   a. Sample a set of portfolio weights.', '   b. Evaluate the performance of the portfolio (returns, variance).', '   c. Update the surrogate model with new observations.', '   d. Optimize the acquisition function to propose new portfolio weights.', '5. Repeat until convergence or a set number of iterations.', '6. Execute the final portfolio weights in the market.']\n",
      "\n",
      "--- How to Use / Limitations ---\n",
      "This strategy requires historical price data for the assets in the portfolio to calculate returns. Key parameters to tune include the number of iterations for optimization and the choice of surrogate model (GP or TPE). The assumption is that the market conditions are stable enough for the optimization process to yield meaningful results. Important limitations include potential overfitting to historical data and the need for sufficient computational resources to run Bayesian optimization. Additionally, the strategy may not perform well in highly volatile or rapidly changing market environments.\n",
      "\n",
      "--- Python Code Outline ---\n",
      "```python\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from sklearn.gaussian_process import GaussianProcessRegressor\n",
      "from skopt import gp_minimize\n",
      "\n",
      "# Placeholder function for evaluating portfolio performance\n",
      "def evaluate_portfolio(weights, returns):\n",
      "    portfolio_return = np.dot(weights, returns.mean())\n",
      "    portfolio_variance = np.dot(weights.T, np.dot(np.cov(returns.T), weights))\n",
      "    return portfolio_return, portfolio_variance\n",
      "\n",
      "# Bayesian optimization function\n",
      "def optimize_portfolio(returns, n_iterations):\n",
      "    # Initialize variables\n",
      "    best_weights = None\n",
      "    best_performance = float('-inf')\n",
      "\n",
      "    # Loop for Bayesian optimization\n",
      "    for i in range(n_iterations):\n",
      "        # Sample portfolio weights\n",
      "        weights = np.random.dirichlet(np.ones(len(returns.columns)))\n",
      "        # Evaluate portfolio\n",
      "        portfolio_return, portfolio_variance = evaluate_portfolio(weights, returns)\n",
      "        # Calculate performance metric (e.g., Sharpe Ratio)\n",
      "        performance = portfolio_return / np.sqrt(portfolio_variance)\n",
      "\n",
      "        # Update best performance\n",
      "        if performance > best_performance:\n",
      "            best_performance = performance\n",
      "            best_weights = weights\n",
      "\n",
      "        # Update surrogate model (placeholder)\n",
      "        # Here we would update our GP or TPE model with new observations\n",
      "\n",
      "    return best_weights, best_performance  # Return optimized weights and performance\n",
      "\n",
      "# Example usage\n",
      "# Load historical returns data (placeholder)\n",
      "# returns_data = pd.read_csv('returns.csv')\n",
      "# optimized_weights, optimized_performance = optimize_portfolio(returns_data, n_iterations=100)\n",
      "# print('Optimized Weights:', optimized_weights)\n",
      "# print('Optimized Performance:', optimized_performance)  # Reference to [ID: 2504.13529v1]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "async def test_strategy_generation(paper_id, prompt):\n",
    "    \"\"\"Tests generating a trading strategy (POST /strategy/)\"\"\"\n",
    "    print(f\"\\n--- Testing POST /strategy/ ---\")\n",
    "    if not paper_id:\n",
    "        print(\"No paper ID available for Strategy Generation test. Skipping.\")\n",
    "        return\n",
    "    # Check if detailed_paper was successfully populated\n",
    "    if not detailed_paper or not detailed_paper.get(\"content\"):\n",
    "         print(\"Detailed paper info (with content) not retrieved in previous step. Skipping Strategy Generation.\")\n",
    "         print(\"(This might happen if get_details timed out or failed)\")\n",
    "         return\n",
    "\n",
    "    print(f\"Using Paper ID: {paper_id}\")\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    start_time = time.time()\n",
    "    strategy_result_data = None\n",
    "\n",
    "    payload = {\"paper_ids\": [paper_id], \"strategy_prompt\": prompt}\n",
    "\n",
    "    async with httpx.AsyncClient(timeout=180.0) as client: # Even longer timeout for strategy generation\n",
    "        try:\n",
    "            response = await client.post(f\"{API_BASE_URL}/strategy/\", json=payload)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            print(f\"Status code: {response.status_code}\")\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"Response time: {elapsed:.2f} seconds\")\n",
    "\n",
    "            strategy_response = response.json() # Response is StrategyGenerationResponse model\n",
    "            strategy_result_data = strategy_response\n",
    "            print(f\"\\nGeneration Notes: {strategy_response.get('notes')}\")\n",
    "            print(f\"Context Paper IDs Used: {strategy_response.get('context_paper_ids')}\")\n",
    "\n",
    "            # Display the structured strategy output nicely\n",
    "            strategy_output = strategy_response.get('strategy')\n",
    "            if strategy_output:\n",
    "                print(\"\\n--- Strategy Description ---\")\n",
    "                print(strategy_output.get('strategy_description', 'N/A'))\n",
    "                print(\"\\n--- Pseudocode / Logic ---\")\n",
    "                print(strategy_output.get('pseudocode', 'N/A'))\n",
    "                print(\"\\n--- How to Use / Limitations ---\")\n",
    "                print(strategy_output.get('how_to_use', 'N/A'))\n",
    "                print(\"\\n--- Python Code Outline ---\")\n",
    "                print(f\"```python\\n{strategy_output.get('python_code', '# N/A')}\\n```\")\n",
    "            else:\n",
    "                # This might happen if 'notes' indicated failure\n",
    "                print(\"No structured strategy output found in response.\")\n",
    "\n",
    "        except httpx.HTTPStatusError as e:\n",
    "            print(f\"HTTP Error: {e.response.status_code}\")\n",
    "            try:\n",
    "                 err_detail = e.response.json().get('detail', e.response.text)\n",
    "                 print(f\"Detail: {err_detail}\")\n",
    "                 if e.response.status_code == 404 and \"not found in the cache\" in err_detail:\n",
    "                     print(\"(This confirms the check for cached papers is working)\")\n",
    "            except: print(f\"Body: {e.response.text}\")\n",
    "        except httpx.RequestError as e:\n",
    "            print(f\"Request Error: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {type(e).__name__}: {e}\")\n",
    "\n",
    "    # print_json(strategy_result_data, title=\"Full Strategy Generation Response\") # Optional: Print raw JSON\n",
    "\n",
    "strategy_prompt_example = f\"Generate a simple strategy based on the core concept mentioned in the abstract or objective of paper {paper_id_to_test}. Keep it high level.\"\n",
    "await test_strategy_generation(paper_id_to_test, strategy_prompt_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
