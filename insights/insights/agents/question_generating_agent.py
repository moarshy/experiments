import logging
import json
from typing import List, Dict, Any
from enum import Enum, auto
from pydantic import BaseModel, Field
import string

# Import from your existing module
from openai_utils import call_openai_api

logger = logging.getLogger(__name__)

class QuestionCategory(str, Enum):
    """Categories for analysis questions."""
    TREND_ANALYSIS = "trend analysis"
    COMPARISON = "comparison"
    AGGREGATION = "aggregation"
    ANOMALY_DETECTION = "anomaly detection"
    CORRELATION = "correlation" 
    DISTRIBUTION = "distribution"
    FORECASTING = "forecasting"

class AgentRole(str, Enum):
    """Roles for the LLM when generating content."""
    # Data roles
    DATA_ANALYST = "data_analyst"
    DATA_SCIENTIST = "data_scientist"
    BUSINESS_ANALYST = "business_analyst"
    DATABASE_EXPERT = "database_expert"
    # Business roles
    BUSINESS_ANALYST = "business analyst"
    MARKETING_SPECIALIST = "marketing specialist"
    FINANCIAL_ANALYST = "financial analyst"
    SALES_MANAGER = "sales manager"
    PRODUCT_MANAGER = "product manager"
    OPERATIONS_MANAGER = "operations manager"
    SUPPLY_CHAIN_ANALYST = "supply chain analyst"
    HR_ANALYST = "human resources analyst"
    CUSTOMER_SUCCESS_MANAGER = "customer success manager"

class PromptTemplate(str, Enum):
    """Templates for system prompts."""
    QUESTION_GENERATION = """
    You are an expert {role} who specializes in formulating analytical questions.
    Your task is to generate insightful, specific analysis questions based on a user query and a database summary.
    
    For each question:
    1. Focus on generating questions that can be answered with SQL queries
    2. Make questions specific and actionable (not vague or general)
    3. Ensure questions are relevant to the user's original query
    4. Tailor questions to the actual database structure provided
    5. Assign a relevance score (0.0-1.0) indicating how directly the question relates to the user query
    6. Categorize each question using one of the following categories: {categories}
    7. Include the specific tables and columns needed to answer each question
    
    Aim for a diverse set of questions that explore different aspects of the data.
    """

class AnalysisQuestion(BaseModel):
    """Model for a single analysis question."""
    question_id: str
    question_text: str
    relevance_score: float = Field(ge=0.0, le=1.0)
    category: QuestionCategory
    related_tables: List[str] = Field(default_factory=list)
    related_columns: List[str] = Field(default_factory=list)

class GeneratedQuestions(BaseModel):
    """Model for the complete set of generated questions."""
    questions: List[AnalysisQuestion]
    total_questions: int

class QuestionGeneratingAgent:
    """
    Agent for generating analysis questions based on database summary and user query.
    
    This agent explores the database structure and suggests relevant questions
    that could lead to valuable insights.
    """
    
    def __init__(self, 
                 min_questions: int = 10, 
                 max_questions: int = 30,
                 agent_role: AgentRole = AgentRole.DATA_ANALYST):
        """
        Initialize the Question Generating Agent.
        
        Args:
            min_questions: Minimum number of questions to generate
            max_questions: Maximum number of questions to generate
            agent_role: The role to use in the system prompt
        """
        self.min_questions = min_questions
        self.max_questions = max_questions
        self.agent_role = agent_role
        
    def _build_system_prompt(self, template: PromptTemplate) -> str:
        """
        Build a system prompt from a template.
        
        Args:
            template: The template to use
            
        Returns:
            The formatted system prompt
        """
        categories_str = ", ".join([cat.value for cat in QuestionCategory])
        return template.value.format(
            role=self.agent_role.value.replace("_", " "),
            categories=categories_str
        )
        
    def _generate_question_id(self, index: int) -> str:
        """
        Generate a unique question ID.
        
        Args:
            index: The question number
            
        Returns:
            A formatted question ID (e.g., Q001)
        """
        return f"Q{str(index+1).zfill(3)}"
        
    def generate_questions(self, user_query: str, db_summary: Dict[str, Any]) -> GeneratedQuestions:
        """
        Generate analysis questions based on user query and database summary.
        
        Args:
            user_query: The original query from the user
            db_summary: The summary generated by DatabaseSummaryAgent
            
        Returns:
            A list of generated analysis questions
        """
        # Determine an appropriate number of questions based on database complexity
        num_tables = len(db_summary.get("technical_summary", {}).get("tables", []))
        
        # Scale number of questions based on database size, within limits
        target_questions = min(max(self.min_questions, num_tables * 2), self.max_questions)
        
        # Build the system prompt from template
        system_prompt = self._build_system_prompt(PromptTemplate.QUESTION_GENERATION)
        
        user_prompt = f"""
        USER QUERY: "{user_query}"
        
        DATABASE SUMMARY:
        {json.dumps(db_summary, indent=2)}
        
        Based on the above information, generate {target_questions} different analytical questions.
        For each question, consider both:
        - What would directly answer the user's query
        - What additional insights might be valuable related to the query
        
        Format each question as a JSON object with the following structure:
        {{
            "question_id": "Q001",  // Unique ID starting with Q followed by a number
            "question_text": "The specific analytical question text",
            "relevance_score": 0.85,  // A number between 0 and 1 indicating relevance to the original query
            "category": "One of: {categories}",
            "related_tables": ["specific tables needed to answer this question"],
            "related_columns": ["specific columns needed to answer this question"]
        }}
        
        Return a JSON array of these question objects.
        """.format(categories=", ".join([cat.value for cat in QuestionCategory]))
        
        result = call_openai_api(
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            response_model=List[AnalysisQuestion],
            temperature=0.7
        )
        
        if not result or not isinstance(result, list):
            logger.error("Failed to generate analysis questions")
            return GeneratedQuestions(questions=[], total_questions=0)
        
        # Ensure question IDs are consistently formatted
        for i, question in enumerate(result):
            question.question_id = self._generate_question_id(i)
        
        # Order questions by relevance score
        sorted_questions = sorted(result, key=lambda q: q.relevance_score, reverse=True)
        
        return GeneratedQuestions(
            questions=sorted_questions,
            total_questions=len(sorted_questions)
        )

def main(user_query: str, db_summary_path: str, role: str = "data_analyst") -> Dict[str, Any]:
    """
    Entry point function to run the Question Generating Agent.
    
    Args:
        user_query: The user's original query
        db_summary_path: Path to a JSON file containing the database summary
        role: The agent role to use (data_analyst, data_scientist, business_analyst, database_expert)
        
    Returns:
        Dictionary containing the generated questions
    """
    # Load database summary
    with open(db_summary_path, 'r') as f:
        db_summary = json.load(f)
    
    # Handle the role parameter
    try:
        agent_role = AgentRole(role)
    except ValueError:
        logger.warning(f"Invalid role '{role}', using default 'data_analyst'")
        agent_role = AgentRole.DATA_ANALYST
    
    # Create question generating agent
    agent = QuestionGeneratingAgent(agent_role=agent_role)
    
    # Generate questions
    questions_response = agent.generate_questions(user_query, db_summary)
    
    return questions_response.model_dump()
    
if __name__ == "__main__":
    import sys
    import json
    
    if len(sys.argv) < 3:
        print("Usage: python question_generating_agent.py <user_query> <path_to_db_summary.json> [role]")
        sys.exit(1)
    
    role = sys.argv[3] if len(sys.argv) > 3 else "data_analyst"    
    result = main(sys.argv[1], sys.argv[2], role)
    print(json.dumps(result, indent=2))