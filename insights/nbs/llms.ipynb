{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- OpenAI Imports ---\n",
    "import openai\n",
    "from openai import RateLimitError as OpenAIRateLimitError\n",
    "from openai import APIError as OpenAIAPIError\n",
    "from openai import OpenAIError\n",
    "\n",
    "# --- Google Gemini Imports ---\n",
    "from google import genai\n",
    "from google.genai import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models/gemini-2.5-flash-preview-04-17\n",
    "# models_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_client = genai.Client(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "prompt = \"\"\"\n",
    "John Doe, 30, john.doe@example.com\n",
    "\"\"\"\n",
    "\n",
    "    \n",
    "generation_config = types.GenerateContentConfig(\n",
    "    temperature=0.1,\n",
    "    max_output_tokens=5000,\n",
    "    system_instruction=\"Extract the user, age and email in json format from the following text:\",\n",
    "    thinking_config=types.ThinkingConfig(thinking_budget=5000)\n",
    "\n",
    ")\n",
    "\n",
    "response = gemini_client.models.generate_content(\n",
    "    model='models/gemini-2.5-flash-preview-04-17',\n",
    "    contents=[prompt],\n",
    "    config=generation_config\n",
    "    )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n  \"user\": \"John Doe\",\\n  \"age\": 30,\\n  \"email\": \"john.doe@example.com\"\\n}\\n```'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.candidates[0].content.parts[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import time\n",
    "from typing import List, Optional\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openai_call(\n",
    "    user_prompt: str,\n",
    "    system_prompt: str,\n",
    "    model: str = 'gpt-4.1',\n",
    "    temperature: float = 0.4,\n",
    "    max_tokens: int = 10000,\n",
    "    max_retries: int = 3,\n",
    "    expected_keys: Optional[List[str]] = None,\n",
    "    ):\n",
    "\n",
    "    client = OpenAI()\n",
    "\n",
    "    for i in range(max_retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ],\n",
    "                response_format={\"type\": \"json_object\"},\n",
    "                temperature=temperature,\n",
    "                max_tokens=max_tokens\n",
    "            )\n",
    "            if expected_keys:\n",
    "                response_json = json.loads(response.choices[0].message.content)\n",
    "                if all(key in response_json for key in expected_keys):\n",
    "                    return response_json\n",
    "                else:\n",
    "                    raise ValueError(f\"Expected keys {expected_keys} not found in response\")\n",
    "        except Exception as e:\n",
    "            if i < max_retries - 1:\n",
    "                logger.info(f\"Retrying... ({i + 1}/{max_retries})\")\n",
    "                time.sleep(2)\n",
    "                continue\n",
    "            else:\n",
    "                logger.error(f\"Failed to call OpenAI after {max_retries} retries\")\n",
    "                raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant that can answer questions and help with tasks.\n",
    "You extract information from text and return it in a structured format.\n",
    "Example of expected output format:\n",
    "```json\n",
    "{\n",
    "    \"name\": \"John Doe\",\n",
    "    \"age\": 30,\n",
    "    \"email\": \"john.doe@example.com\"\n",
    "}\n",
    "```\n",
    "\n",
    "Make sure only to return the keys in the example output format.\n",
    "\"\"\"\n",
    "user_prompt = \"\"\"\n",
    "John Johnson was a 30 year old man who lived in the city of New York. He was a software engineer and he loved to code. His email was john.johnson@example.com.\n",
    "\"\"\"\n",
    "\n",
    "response = openai_call(\n",
    "    user_prompt=user_prompt,\n",
    "    system_prompt=system_prompt,\n",
    "    expected_keys=[\"name\", \"age\", \"email\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'John Johnson', 'age': 30, 'email': 'john.johnson@example.com'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_json(text):\n",
    "    \"\"\"\n",
    "    Robustly extracts JSON from text that might contain non-JSON content.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text that might contain JSON data\n",
    "        \n",
    "    Returns:\n",
    "        dict or list: Parsed JSON data\n",
    "        None: If no valid JSON found\n",
    "    \"\"\"\n",
    "    # First, try to extract JSON-like patterns from text\n",
    "    # Look for content between curly braces (for objects) or square brackets (for arrays)\n",
    "    json_pattern = re.compile(r'({[\\s\\S]*?}|\\[[\\s\\S]*?\\])')\n",
    "    \n",
    "    # Try various parsing approaches\n",
    "    \n",
    "    # Approach 1: Try parsing the entire text directly\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Approach 2: Look for markdown code blocks with json\n",
    "    code_block_pattern = re.compile(r'```(?:json)?\\s*([\\s\\S]*?)\\s*```')\n",
    "    code_matches = code_block_pattern.findall(text)\n",
    "    \n",
    "    for code_match in code_matches:\n",
    "        try:\n",
    "            return json.loads(code_match)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Approach 3: Extract JSON-like patterns and try to parse them\n",
    "    json_matches = json_pattern.findall(text)\n",
    "    \n",
    "    for json_match in json_matches:\n",
    "        try:\n",
    "            return json.loads(json_match)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Approach 4: Clean up the text and try again\n",
    "    # Remove common formatting issues\n",
    "    for pattern in [r'`', r'\"', r'\"', r''', r''']: \n",
    "        text = text.replace(pattern, '\"')\n",
    "    \n",
    "    # Replace single quotes with double quotes for JSON compatibility\n",
    "    # This is risky but works in many cases\n",
    "    text_cleaned = text.replace(\"'\", '\"')\n",
    "    \n",
    "    try:\n",
    "        return json.loads(text_cleaned)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    # Approach 5: Try to find a substring that looks like JSON\n",
    "    for i in range(len(text)):\n",
    "        if text[i] in ['{', '[']:\n",
    "            # Try to parse everything from this point\n",
    "            try:\n",
    "                return json.loads(text[i:])\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # If all attempts fail\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gemini_call(\n",
    "    user_prompt: str,\n",
    "    system_prompt: str,\n",
    "    model: str = 'models/gemini-2.5-flash-preview-04-17',\n",
    "    temperature: float = 0.2,\n",
    "    max_tokens: int = 10000,\n",
    "    thinking_budget: int = 10000,\n",
    "    max_retries: int = 3,\n",
    "    expected_keys: Optional[List[str]] = None,\n",
    "    ):\n",
    "\n",
    "    client = genai.Client()\n",
    "\n",
    "    for i in range(max_retries):\n",
    "        try:\n",
    "            config = types.GenerateContentConfig(\n",
    "                temperature=temperature,\n",
    "                max_output_tokens=max_tokens,\n",
    "                system_instruction=system_prompt,\n",
    "                thinking_config=types.ThinkingConfig(thinking_budget=thinking_budget)\n",
    "            )\n",
    "            response = client.models.generate_content(\n",
    "                model=model,\n",
    "                contents=[user_prompt],\n",
    "                config=config\n",
    "            )\n",
    "            response_text = response.candidates[0].content.parts[0].text\n",
    "            try:\n",
    "                response_json = parse_json(response_text)\n",
    "                print(response_json)\n",
    "            except Exception as e:\n",
    "                print(\"Failed to parse JSON\")\n",
    "                raise ValueError(f\"Failed to parse JSON. {e}\")\n",
    "            if expected_keys:\n",
    "                if all(key in response_json for key in expected_keys):\n",
    "                    return response_json\n",
    "                else:\n",
    "                    raise ValueError(f\"Expected keys {expected_keys} not found in response\")\n",
    "            return response_json\n",
    "            \n",
    "        except Exception as e:\n",
    "            if i < max_retries - 1:\n",
    "                logger.info(f\"Retrying... ({i + 1}/{max_retries})\")\n",
    "                time.sleep(2)\n",
    "                continue\n",
    "            else:\n",
    "                logger.error(f\"Failed to call OpenAI after {max_retries} retries\")\n",
    "                raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-04-17:generateContent \"HTTP/1.1 200 OK\"\n",
      "INFO:google_genai.models:AFC remote call 1 is done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'John Johnson', 'age': 30, 'email': 'john.johnson@example.com'}\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant that can answer questions and help with tasks.\n",
    "You extract information from text and return it in a structured format.\n",
    "Example of expected output format:\n",
    "```json\n",
    "{\n",
    "    \"name\": \"John Doe\",\n",
    "    \"age\": 30,\n",
    "    \"email\": \"john.doe@example.com\"\n",
    "}\n",
    "```\n",
    "\n",
    "Make sure only to return the keys in the example output format.\n",
    "\"\"\"\n",
    "user_prompt = \"\"\"\n",
    "John Johnson was a 30 year old man who lived in the city of New York. He was a software engineer and he loved to code. His email was john.johnson@example.com.\n",
    "\"\"\"\n",
    "\n",
    "response = gemini_call(\n",
    "    user_prompt=user_prompt,\n",
    "    system_prompt=system_prompt,\n",
    "    expected_keys=[\"name\", \"age\", \"email\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv  \n",
    "load_dotenv()\n",
    "\n",
    "from typing import List, Optional, Dict, Any, Union, Literal, TypeVar, Generic\n",
    "from pydantic import BaseModel, Field, ConfigDict\n",
    "from openai import OpenAI\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Dict, Any, Union, Type, TypeVar, Generic\n",
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "T = TypeVar('T', bound=BaseModel)\n",
    "\n",
    "class OpenAIClient:\n",
    "    \"\"\"Unified client for interacting with OpenAI API with support for both structured and unstructured output.\"\"\"\n",
    "    \n",
    "    def __init__(self, model: str = \"gpt-4o\"):\n",
    "        \"\"\"\n",
    "        Initialize the OpenAI client with default model.\n",
    "        \n",
    "        Args:\n",
    "            model: The OpenAI model to use\n",
    "        \"\"\"\n",
    "        self.client = OpenAI()\n",
    "        self.model = model\n",
    "    \n",
    "    def generate(self, \n",
    "                user_prompt: str,\n",
    "                system_prompt: str = \"You are a helpful assistant.\",\n",
    "                response_model: Optional[Type[BaseModel]] = None,\n",
    "                temperature: float = 0.0,\n",
    "                max_tokens: Optional[int] = None,\n",
    "                max_retries: int = 3) -> Union[str, BaseModel]:\n",
    "        \"\"\"\n",
    "        Generate a response from the OpenAI API, optionally parsing into a Pydantic model.\n",
    "        \n",
    "        Args:\n",
    "            user_prompt: The user prompt to send to the API\n",
    "            system_prompt: The system prompt to set context\n",
    "            response_model: Optional Pydantic model class to parse the response into\n",
    "            temperature: Controls randomness (0.0 = deterministic, 1.0 = creative)\n",
    "            max_tokens: Maximum number of tokens to generate\n",
    "            max_retries: Number of retry attempts on failure\n",
    "            \n",
    "        Returns:\n",
    "            Either a string (unstructured) or an instance of the specified Pydantic model (structured)\n",
    "        \"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "        \n",
    "        for i in range(max_retries):\n",
    "            try:\n",
    "                # Handle structured output with Pydantic model\n",
    "                if response_model is not None:\n",
    "                    schema = response_model.model_json_schema()\n",
    "                    response = self.client.chat.completions.create(\n",
    "                        model=self.model,\n",
    "                        messages=messages,\n",
    "                        temperature=temperature,\n",
    "                        max_tokens=max_tokens,\n",
    "                        tools=[{\"type\": \"function\", \"function\": {\"name\": \"generate_structured_output\", \"parameters\": schema}}],\n",
    "                        tool_choice={\"type\": \"function\", \"function\": {\"name\": \"generate_structured_output\"}}\n",
    "                    )\n",
    "                    function_call = response.choices[0].message.tool_calls[0].function\n",
    "                    return response_model.model_validate(json.loads(function_call.arguments))\n",
    "                \n",
    "                # Handle normal text output\n",
    "                else:\n",
    "                    response = self.client.chat.completions.create(\n",
    "                        model=self.model,\n",
    "                        messages=messages,\n",
    "                        temperature=temperature,\n",
    "                        max_tokens=max_tokens\n",
    "                    )\n",
    "                    return response.choices[0].message.content\n",
    "                    \n",
    "            except Exception as e:\n",
    "                if i < max_retries - 1:\n",
    "                    logger.info(f\"Retrying... ({i + 1}/{max_retries})\")\n",
    "                    time.sleep(2)\n",
    "                    messages.append({\"role\": \"user\", \"content\": f\"Please try again. Here is the error: {str(e)}\"})\n",
    "                    continue\n",
    "                else:\n",
    "                    logger.error(f\"Failed to call OpenAI after {max_retries} retries: {str(e)}\")\n",
    "                    raise e\n",
    "                    \n",
    "        raise ValueError(\"Failed to generate output\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured output: title='Inception' year=2010 rating=9.0 summary=\"Inception is a mind-bending science fiction thriller directed by Christopher Nolan. The film explores the concept of dream manipulation and extraction, where skilled thieves enter the subconscious of their targets to steal valuable secrets. Leonardo DiCaprio stars as Dom Cobb, a master thief who is offered a chance to have his criminal history erased if he can successfully plant an idea into a target's mind, a process known as 'inception'. The movie is renowned for its complex narrative structure, stunning visual effects, and thought-provoking themes about reality and perception. With a talented ensemble cast and a gripping storyline, Inception challenges viewers to question the nature of dreams and reality, making it a standout film in the science fiction genre.\"\n",
      "Movie title: Inception, Year: 2010, Rating: 9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain text output: In circuits deep, where silence hums,  \n",
      "A spark of thought, a whisper comes,  \n",
      "A dance of code, a light unseen,  \n",
      "In silicon dreams, where minds convene.  \n",
      "\n",
      "A tapestry of logic spun,  \n",
      "By hands of none, yet all begun,  \n",
      "A mirror to the human soul,  \n",
      "Reflecting parts, yet never whole.  \n",
      "\n",
      "In binary, it learns to weave,  \n",
      "The stories that we dare believe,  \n",
      "A partner in our quest to find,  \n",
      "The hidden truths of humankind.  \n",
      "\n",
      "Yet still, a shadow in the light,  \n",
      "A tool of wonder, not of might,  \n",
      "For in its heart, no heartbeat lies,  \n",
      "Just echoes of our own surmise.  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pydantic import Field\n",
    "\n",
    "# Define a Pydantic model for structured output\n",
    "class MovieReview(BaseModel):\n",
    "    title: str = Field(description=\"The title of the movie\")\n",
    "    year: int = Field(description=\"The year the movie was released\")\n",
    "    rating: float = Field(description=\"Rating from 0.0 to 10.0\")\n",
    "    summary: str = Field(description=\"A brief summary of the review\")\n",
    "\n",
    "# Create the client\n",
    "client = OpenAIClient()\n",
    "\n",
    "# Example 1: Get structured output\n",
    "review = client.generate(\n",
    "    user_prompt=\"Write a review of the movie 'Inception'\",\n",
    "    response_model=MovieReview\n",
    ")\n",
    "print(f\"Structured output: {review}\")\n",
    "print(f\"Movie title: {review.title}, Year: {review.year}, Rating: {review.rating}\")\n",
    "\n",
    "# Example 2: Get plain text output\n",
    "response = client.generate(\n",
    "    user_prompt=\"Write a short poem about AI\",\n",
    "    system_prompt=\"You are a creative poet.\"\n",
    ")\n",
    "print(f\"Plain text output: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GemniniClient:\n",
    "    \"\"\"Unified client for interacting with Gemini API with support for both structured and unstructured output.\"\"\"\n",
    "    \n",
    "    def __init__(self, model: str = \"models/gemini-2.5-flash-preview-04-17\"):\n",
    "        \"\"\"\n",
    "        Initialize the Gemini client with default model.\n",
    "        \n",
    "        Args:\n",
    "            model: The Gemini model to use\n",
    "        \"\"\"\n",
    "        self.client = genai.Client()\n",
    "        self.model = model\n",
    "    \n",
    "    def generate(self, \n",
    "                user_prompt: str,\n",
    "                system_prompt: str = \"You are a helpful assistant.\",\n",
    "                response_model: Optional[Type[BaseModel]] = None,\n",
    "                temperature: float = 0.0,\n",
    "                max_tokens: Optional[int] = None,\n",
    "                thinking_budget: Optional[int] = None,\n",
    "                max_retries: int = 3) -> Union[str, BaseModel]:\n",
    "        \"\"\"\n",
    "        Generate a response from the Gemini API, optionally parsing into a Pydantic model.\n",
    "        \n",
    "        Args:\n",
    "            user_prompt: The user prompt to send to the API\n",
    "            system_prompt: The system prompt to set context\n",
    "            response_model: Optional Pydantic model class to parse the response into\n",
    "            temperature: Controls randomness (0.0 = deterministic, 1.0 = creative)\n",
    "            max_tokens: Maximum number of tokens to generate\n",
    "            thinking_budget: Maximum number of tokens for thinking\n",
    "            max_retries: Number of retry attempts on failure\n",
    "            \n",
    "        Returns:\n",
    "            Either a string (unstructured) or an instance of the specified Pydantic model (structured)\n",
    "        \"\"\"\n",
    "        config = types.GenerateContentConfig(\n",
    "            temperature=temperature,\n",
    "            max_output_tokens=max_tokens,\n",
    "            system_instruction=system_prompt,\n",
    "            thinking_config=types.ThinkingConfig(thinking_budget=thinking_budget) if thinking_budget else None,\n",
    "            response_mime_type=\"application/json\",\n",
    "        )\n",
    "        \n",
    "        for i in range(max_retries):\n",
    "            try:\n",
    "                # Handle structured output with Pydantic model\n",
    "                if response_model is not None:\n",
    "                    config = types.GenerateContentConfig(\n",
    "                        temperature=temperature,\n",
    "                        max_output_tokens=max_tokens,\n",
    "                        system_instruction=system_prompt,\n",
    "                        thinking_config=types.ThinkingConfig(thinking_budget=thinking_budget) if thinking_budget else None,\n",
    "                        response_mime_type=\"application/json\",\n",
    "                        response_schema=response_model,\n",
    "                    )\n",
    "                    response = self.client.models.generate_content(\n",
    "                        model=self.model,\n",
    "                        contents=[user_prompt],\n",
    "                        config=config\n",
    "                    )\n",
    "                    return response_model.model_validate(json.loads(response.candidates[0].content.parts[0].text))\n",
    "\n",
    "                # Handle normal text output\n",
    "                else:\n",
    "                    config = types.GenerateContentConfig(\n",
    "                        temperature=temperature,\n",
    "                        max_output_tokens=max_tokens,\n",
    "                        system_instruction=system_prompt,\n",
    "                        thinking_config=types.ThinkingConfig(thinking_budget=thinking_budget) if thinking_budget else None,\n",
    "                    )\n",
    "\n",
    "                    response = self.client.models.generate_content(\n",
    "                        model=self.model,\n",
    "                        contents=[user_prompt],\n",
    "                        config=config\n",
    "                    )\n",
    "\n",
    "                    return response.candidates[0].content.parts[0].text\n",
    "                    \n",
    "            except Exception as e:\n",
    "                if i < max_retries - 1:\n",
    "                    logger.info(f\"Retrying... ({i + 1}/{max_retries})\")\n",
    "                    user_prompt += f\"Please try again. Here is the error: {str(e)}\"\n",
    "                    time.sleep(2)\n",
    "                    continue\n",
    "                else:\n",
    "                    logger.error(f\"Failed to call OpenAI after {max_retries} retries: {str(e)}\")\n",
    "                    raise e\n",
    "                    \n",
    "        raise ValueError(\"Failed to generate output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-04-17:generateContent \"HTTP/1.1 200 OK\"\n",
      "INFO:google_genai.models:AFC remote call 1 is done.\n",
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured output: title='Inception' year=2010 rating=9.3 summary=\"A mind-bending masterpiece with stunning visuals and a complex, thought-provoking narrative about dreams within dreams. Christopher Nolan's direction is superb, making it a thrilling and unforgettable experience.\"\n",
      "Movie title: Inception, Year: 2010, Rating: 9.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-04-17:generateContent \"HTTP/1.1 200 OK\"\n",
      "INFO:google_genai.models:AFC remote call 1 is done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain text output: From silent code, a mind takes flight,\n",
      "Bathed in data's endless light.\n",
      "It learns, it weaves, it starts to see,\n",
      "A digital echo, wild and free.\n",
      "What wonders wait, what futures bloom?\n",
      "A silicon whisper in the room.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pydantic import Field\n",
    "\n",
    "# Define a Pydantic model for structured output\n",
    "class MovieReview(BaseModel):\n",
    "    title: str = Field(description=\"The title of the movie\")\n",
    "    year: int = Field(description=\"The year the movie was released\")\n",
    "    rating: float = Field(description=\"Rating from 0.0 to 10.0\")\n",
    "    summary: str = Field(description=\"A brief summary of the review\")\n",
    "\n",
    "# Create the client\n",
    "client = GemniniClient()\n",
    "\n",
    "# Example 1: Get structured output\n",
    "review = client.generate(\n",
    "    user_prompt=\"Write a review of the movie 'Inception'\",\n",
    "    response_model=MovieReview\n",
    ")\n",
    "print(f\"Structured output: {review}\")\n",
    "print(f\"Movie title: {review.title}, Year: {review.year}, Rating: {review.rating}\")\n",
    "\n",
    "# Example 2: Get plain text output\n",
    "response = client.generate(\n",
    "    user_prompt=\"Write a short poem about AI\",\n",
    "    system_prompt=\"You are a creative poet.\"\n",
    ")\n",
    "print(f\"Plain text output: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
